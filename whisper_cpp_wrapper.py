"""
Whisper.cpp Python å°è£…
æä¾›å®Œæ•´çš„ Python API æ¥ä½¿ç”¨ Homebrew å®‰è£…çš„ whisper-cliï¼ˆMetal åŠ é€Ÿï¼‰
"""

import os
import subprocess
import tempfile
import re
from pathlib import Path
from typing import Optional, List, Dict
import json
import threading
import time
from tqdm import tqdm
import ffmpeg


class WhisperCPP:
    """
    Whisper.cpp Python å°è£…ç±»
    ä½¿ç”¨ Metal GPU åŠ é€Ÿçš„ whisper-cli
    """
    
    def __init__(
        self, 
        model_name: str = "large-v3",
        model_dir: Optional[str] = None,
        threads: int = 10,
        language: str = "en"
    ):
        """
        åˆå§‹åŒ– WhisperCPP
        
        Args:
            model_name: æ¨¡å‹åç§° (tiny, base, small, medium, large-v3)
            model_dir: æ¨¡å‹å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸º ~/PycharmProjects/voiceRecognize/models
            threads: ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ŒM4 èŠ¯ç‰‡å»ºè®® 10-12
            language: è½¬å½•è¯­è¨€ï¼Œé»˜è®¤è‹±è¯­
        """
        self.model_name = model_name
        self.threads = threads
        self.language = language
        
        # è®¾ç½®æ¨¡å‹è·¯å¾„
        if model_dir is None:
            model_dir = os.path.expanduser("~/PycharmProjects/voiceRecognize/models")
        self.model_dir = Path(model_dir)
        self.model_path = self.model_dir / f"ggml-{model_name}.bin"
        
        # ç¡®ä¿æ¨¡å‹å­˜åœ¨
        self._ensure_model()
    
    def _ensure_model(self):
        """ç¡®ä¿æ¨¡å‹å·²ä¸‹è½½"""
        if not self.model_path.exists():
            print(f"ä¸‹è½½ {self.model_name} æ¨¡å‹...")
            self.model_dir.mkdir(parents=True, exist_ok=True)
            
            url = f"https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-{self.model_name}.bin"
            subprocess.run(
                ["curl", "-L", url, "-o", str(self.model_path)],
                check=True,
                capture_output=True
            )
            print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {self.model_path}")
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            probe = ffmpeg.probe(audio_path)
            duration = float(probe["format"]["duration"])
            return duration
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {e}")
            return 0
    
    def _convert_to_wav(self, audio_path: str) -> str:
        """
        å°†éŸ³é¢‘è½¬æ¢ä¸º WAV æ ¼å¼ï¼ˆwhisper-cli éœ€è¦ï¼‰
        
        Args:
            audio_path: è¾“å…¥éŸ³é¢‘è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„ WAV æ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºä¸´æ—¶ WAV æ–‡ä»¶
        temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        temp_wav.close()
        
        # ä½¿ç”¨ ffmpeg è½¬æ¢
        subprocess.run([
            "ffmpeg", "-i", audio_path,
            "-ar", "16000",      # 16kHz é‡‡æ ·ç‡
            "-ac", "1",          # å•å£°é“
            "-c:a", "pcm_s16le", # 16-bit PCM
            "-y",                # è¦†ç›–
            temp_wav.name
        ], check=True, capture_output=True)
        
        return temp_wav.name
    
    def transcribe(
        self,
        audio_path: str,
        output_format: str = "txt",
        verbose: bool = True
    ) -> Dict[str, any]:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨ Metal GPU åŠ é€Ÿï¼‰
        
        Args:
            audio_path: è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_format: è¾“å‡ºæ ¼å¼ (txt, srt, vtt, json)
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
            
        Returns:
            åŒ…å«è½¬å½•ç»“æœçš„å­—å…¸
        """
        audio_path_obj = Path(audio_path).resolve()
        audio_path = str(audio_path_obj)
        
        # 1. è®¾å®šæŒä¹…åŒ– JSON è·¯å¾„ (æ–°å»ºå­æ–‡ä»¶å¤¹)
        # ä¾‹å¦‚è¾“å…¥ video.mp4 -> ç”Ÿæˆ video_output/video.json
        output_dir = audio_path_obj.parent / f"{audio_path_obj.stem}_output"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_base = str(output_dir / audio_path_obj.stem)
        json_file = f"{output_base}.json"
        
        # 2. æ£€æŸ¥ç¼“å­˜ï¼šå¦‚æœ JSON å·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
        if os.path.exists(json_file):
            if verbose:
                print(f"âœ¨ å‘ç°å·²æœ‰ JSON ç¼“å­˜: {json_file}")
                print(f"â© è·³è¿‡ AI æ¨ç†ï¼Œç›´æ¥è¿›è¡Œæ™ºèƒ½åˆ†æ®µ...")
            
            if output_format in ["srt", "txt"]:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                processed_text = self._smart_process(data, output_format)
                
                # æ›´æ–°è¾“å‡ºæ–‡ä»¶ï¼ˆè¦†ç›–æ—§çš„ txt/srtï¼‰
                output_file = f"{output_base}.{output_format}"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(processed_text)
                
                return {
                    'text': processed_text,
                    'output_file': output_file,
                    'success': True,
                    'cached': True
                }

        if verbose:
            print(f"ğŸ¤ è½¬å½•éŸ³é¢‘: {audio_path}")
            print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {self.model_name} (Metal åŠ é€Ÿ)")
        
        # 3. æ­£å¸¸æµç¨‹ï¼šè½¬æ¢ä¸º WAV
        if verbose:
            print("ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼...")
        temp_wav = self._convert_to_wav(audio_path)
        
        try:
            # æ„å»ºå‘½ä»¤ - å¼€å¯å…¨åŠŸèƒ½ JSON å’Œå•è¯çº§æ—¶é—´æˆ³
            # ã€æ³¨æ„ã€‘è¿™é‡Œä¸å†ç”¨ tempfileï¼Œè€Œæ˜¯ç›´æ¥è¾“å‡ºåˆ°æºæ–‡ä»¶åŒçº§ç›®å½•
            cmd = [
                "whisper-cli",
                "-m", str(self.model_path),
                "-f", temp_wav,
                "-ojf",               # ã€æ ¸å¿ƒã€‘å¼ºåˆ¶è¾“å‡º Full JSON
                "-of", output_base,   # è¾“å‡ºåˆ°åŒçº§ç›®å½•
                "-t", str(self.threads),
                "-l", self.language,
                "-sow", "true",
                "-pp",
            ]
            
            # åŒæ—¶ä¿ç•™ç”¨æˆ·è¯·æ±‚çš„æ ¼å¼è¾“å‡ºï¼ˆå¦‚æœä¸æ˜¯ JSONï¼‰
            if output_format != "json":
                cmd.append(f"-o{output_format}")
            
            # å¯åŠ¨è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )

            stdout_output = ""
            if verbose:
                print(f"âš¡ å¼€å§‹è½¬å½• M4 æ ¸å¿ƒå…¨åŠ›åŠ é€Ÿä¸­...")
                with tqdm(total=100, desc="è½¬å½•è¿›åº¦", unit="%", ncols=80) as pbar:
                    last_progress = 0
                    # å®æ—¶è¯»å– stderr æ¥è·å–è¿›åº¦
                    while True:
                        line = process.stderr.readline()
                        if not line and process.poll() is not None:
                            break
                        if line:
                            # whisper.cpp è¿›åº¦æ ¼å¼: "whisper_full_with_state: progress =  XX%"
                            if "progress =" in line:
                                try:
                                    progress_match = re.search(r"progress\s*=\s*(\d+)%", line)
                                    if progress_match:
                                        current_progress = int(progress_match.group(1))
                                        if current_progress > last_progress:
                                            pbar.update(current_progress - last_progress)
                                            last_progress = current_progress
                                except Exception:
                                    pass
                    pbar.n = 100
                    pbar.refresh()
            
            # ç­‰å¾…å®Œæˆå¹¶è·å–æ‰€æœ‰è¾“å‡º
            stdout_output, stderr_output = process.communicate()
            
            if process.returncode != 0:
                print(f"âŒ è½¬å½•å¤±è´¥: {stderr_output}")
                return {
                    'text': None,
                    'output_file': None,
                    'success': False,
                    'error': stderr_output
                }

            # å…¼å®¹åç»­ä»£ç ä½¿ç”¨çš„ result å¯¹è±¡
            class Result:
                def __init__(self, stdout):
                    self.stdout = stdout
            result = Result(stdout_output)
            
            # è¯»å–ç»“æœ
            json_file = f"{output_base}.json"
            if os.path.exists(json_file):
                # å¦‚æœæˆ‘ä»¬è¦è¿›è¡Œæ™ºèƒ½å¤„ç†ï¼Œä» JSON è¯»å–å¹¶é‡æ–°ç”Ÿæˆ
                if output_format in ["srt", "txt"]:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    processed_text = self._smart_process(data, output_format)
                    
                    # å†™å›æ–‡ä»¶è¦†ç›–é»˜è®¤ç”Ÿæˆçš„
                    output_file = f"{output_base}.{output_format}"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(processed_text)
                    
                    text = processed_text
                else:
                    output_file = f"{output_base}.{output_format}"
                    with open(output_file, 'r', encoding='utf-8') as f:
                        text = f.read()
                
                if verbose:
                    print(f"âœ… è½¬å½•å®Œæˆ (å·²è¿›è¡Œæ™ºèƒ½è¯­ä¹‰åˆ†æ®µ)ï¼")
                
                return {
                    'text': text,
                    'output_file': output_file,
                    'success': True,
                    'stdout': result.stdout
                }
            else:
                return {
                    'text': None,
                    'output_file': None,
                    'success': False,
                    'error': 'è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ'
                }
        
        finally:
            # åªæ¸…ç†ç”Ÿæˆçš„åŸå§‹ WAV æ–‡ä»¶
            # ç»“æœæ–‡ä»¶ç”±è°ƒç”¨è€…ï¼ˆå¦‚ transcribe_to_fileï¼‰è´Ÿè´£æ¸…ç†æˆ–ç§»åŠ¨
            if os.path.exists(temp_wav):
                try:
                    os.unlink(temp_wav)
                except:
                    pass
    
    def _smart_process(self, data: Dict, output_format: str) -> str:
        """
        åŸºäºå•è¯çº§åˆ«æ—¶é—´æˆ³çš„ç»ˆæåˆ†æ®µé€»è¾‘
        1. æ‘Šå¹³æ‰€æœ‰å•è¯ï¼Œæ— è§†åŸå§‹ç‰‡æ®µ
        2. æŒ‰ç…§è¯­ä¹‰æ ‡ç‚¹å’Œé•¿åº¦ä¸Šé™ï¼Œé‡æ–°ç»„è£…å¥å­
        """
        # å°è¯•ä» Full JSON ä¸­è·å–æ‰€æœ‰å•è¯
        all_words = []
        segments = data.get("transcription", [])
        
        for seg in segments:
            tokens = seg.get("tokens", [])
            for tk in tokens:
                text = tk.get("text", "")
                
                # ã€å¼ºåŒ–æ¸…ç†ã€‘ç§»é™¤æ‰€æœ‰ Whisper ç‰¹æ®Šæ ‡è®°
                text = re.sub(r'\[_?BEG_?\]|\[_?TT_\d+\]|\[_?EOT_?\]|\[_?SOT_?\]', '', text)
                
                if not text.strip():
                    continue
                
                # ã€é‡è¦ä¿®å¤ã€‘è·å–æ—¶é—´æˆ³ï¼Œä¸è¿›è¡Œæš´åŠ›å›é€€åˆ° Segment
                # å¦‚æœ token è‡ªèº«æ²¡æœ‰ offsetsï¼Œè¯´æ˜å¯èƒ½æ˜¯æ ‡ç‚¹ï¼Œè¿™ä¸åº”è¯¥ç»§æ‰¿æ•´ä¸ª Segment çš„ç»“æŸæ—¶é—´
                tk_offsets = tk.get("offsets", {})
                start = tk_offsets.get("from")
                end = tk_offsets.get("to")
                
                # å¦‚æœå½“å‰è¯æ²¡æœ‰æ—¶é—´æˆ³ï¼ˆå¦‚æ ‡ç‚¹ï¼‰ï¼Œæš‚æ—¶æ ‡è®°ä¸º Noneï¼Œç¨åæ’å€¼
                all_words.append({
                    "text": text,
                    "start": start,
                    "end": end,
                    "seg_start_fallback": seg["offsets"]["from"], # ä»…ç”¨äºå…œåº•
                    "seg_end_fallback": seg["offsets"]["to"] 
                })

        if not all_words:
            return ""

        # --- æ—¶é—´æˆ³ä¿®å¤/æ’å€¼ (Linear Interpolation) ---
        for i in range(len(all_words)):
            word = all_words[i]
            
            # 1. ä¿®å¤ Start
            if word["start"] is None:
                if i > 0:
                    # ç´§æ¥ä¸Šä¸€ä¸ªè¯ç»“æŸ
                    word["start"] = all_words[i-1]["end"]
                else:
                    # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªè¯ï¼Œè¢«è¿«ä½¿ç”¨ Segment å¼€å§‹
                    word["start"] = word["seg_start_fallback"]
            
            # 2. ä¿®å¤ End
            if word["end"] is None:
                if word["start"] is not None:
                     # å‡è®¾å®ƒæ˜¯æ ‡ç‚¹ï¼ŒæŒç»­æ—¶é—´æçŸ­ï¼Œæˆ–è€…å°±ç­‰äº start
                     word["end"] = word["start"]
                else:
                     # ä¾ç„¶æ— æ³•ç¡®å®šï¼Œç¨åå¤„ç†
                     pass

        # äºŒæ¬¡éå†ç¡®ä¿æ²¡æœ‰ None (é’ˆå¯¹è¿ç»­ç¼ºå¤±çš„æƒ…å†µ)
        for i in range(len(all_words)):
            if all_words[i]["end"] is None:
                 # å‘åå¯»æ‰¾æœ€è¿‘çš„æœ‰æ•ˆ start
                 valid_next_start = None
                 for j in range(i+1, len(all_words)):
                     if all_words[j]["start"] is not None:
                         valid_next_start = all_words[j]["start"]
                         break
                 
                 if valid_next_start:
                     all_words[i]["end"] = valid_next_start
                     all_words[i]["start"] = valid_next_start # æŒ¤å‹æˆç¬é—´
                 else:
                     # ç¡®å®æ˜¯å…¨æ®µæœ€åäº†ï¼Œåªèƒ½ç”¨ segment end
                     all_words[i]["end"] = all_words[i]["seg_end_fallback"]
                     if all_words[i]["start"] is None:
                         all_words[i]["start"] = all_words[i]["end"]

        if not all_words:
            return ""

        merged_segments = []
        current_words_buffer = []  # æ”¹ç”¨åˆ—è¡¨æš‚å­˜å•è¯å¯¹è±¡ï¼Œæ–¹ä¾¿å›æº¯
        current_len = 0
        
        MAX_CHARS = 90      # ç”¨æˆ·è®¾å®šé•¿åº¦

        for i, word in enumerate(all_words):
            text = word["text"]
            w_len = len(text)
            
            # --- é•¿åº¦é¢„åˆ¤ ---
            if current_len + w_len > MAX_CHARS:
                # ã€è§¦å‘å›æº¯åˆ‡åˆ†é€»è¾‘ã€‘
                split_index = -1
                
                # å€’åºå¯»æ‰¾æœ€è¿‘çš„æ ‡ç‚¹ç¬¦å· (é€—å·ã€å¥å·ç­‰)
                # æˆ‘ä»¬å¸Œæœ›åˆ‡åˆ†ç‚¹ä¸è¦å¤ªé å‰ï¼ˆä¿ç•™è‡³å°‘ 1/3 çš„é•¿åº¦ï¼‰ï¼Œå¦åˆ™ç¬¬ä¸€è¡Œå¤ªçŸ­
                min_keep_len = int(len(current_words_buffer) * 0.4)
                
                for j in range(len(current_words_buffer) - 1, min_keep_len, -1):
                    w_text = current_words_buffer[j]["text"].strip()
                    # æ£€æŸ¥å•è¯ç»“å°¾æ˜¯å¦æ˜¯æ ‡ç‚¹
                    if w_text and w_text[-1] in ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ', ',', 'ï¼Œ', ':', ';']:
                        split_index = j
                        break
                
                if split_index != -1:
                    # æ–¹æ¡ˆ Aï¼šæ‰¾åˆ°äº†å®Œç¾çš„æ ‡ç‚¹åˆ‡åˆ†ç‚¹
                    seg1_words = current_words_buffer[:split_index+1]
                    seg2_words = current_words_buffer[split_index+1:]
                    
                    merged_segments.append({
                        "text": "".join([w["text"] for w in seg1_words]).strip(),
                        "start": seg1_words[0]["start"],
                        "end": seg1_words[-1]["end"]
                    })
                    
                    # å‰©ä¸‹çš„è¯ + å½“å‰æ–°è¯ ç»„æˆä¸‹ä¸€å¥çš„å¼€å¤´
                    current_words_buffer = seg2_words + [word]
                    current_len = sum(len(w["text"]) for w in current_words_buffer)
                    continue
                
                else:
                    # æ–¹æ¡ˆ Bï¼šæ²¡æ‰¾åˆ°æ ‡ç‚¹ï¼Œåªèƒ½ç¡¬åˆ‡
                    # ä½†è¦åšä¸€ä¸ªä¿æŠ¤ï¼šå¦‚æœå½“å‰è¯æ˜¯æ ‡ç‚¹ï¼Œå¿…é¡»æŠŠå®ƒè´´åˆ°ä¸Šä¸€è¡Œï¼Œä¸èƒ½è®©å®ƒä½œä¸ºæ–°è¡Œå¼€å¤´
                    is_bad_start = text.strip() and text.strip()[0] in ['.', '!', '?', ',', 'ï¼Œ', ':']
                    
                    if not is_bad_start:
                        # æ­£å¸¸ç¡¬åˆ‡ï¼šBuffer é‡Œçš„å½’ä¸Šä¸€è¡Œï¼Œå½“å‰è¯å½’ä¸‹ä¸€è¡Œ
                        if current_words_buffer:
                            merged_segments.append({
                                "text": "".join([w["text"] for w in current_words_buffer]).strip(),
                                "start": current_words_buffer[0]["start"],
                                "end": current_words_buffer[-1]["end"]
                            })
                        current_words_buffer = [word]
                        current_len = w_len
                        continue
                    else:
                        # è¿™æ˜¯ä¸€ä¸ªæ ‡ç‚¹ï¼Œè™½ç„¶è¶…é•¿äº†ï¼Œä½†å¿…é¡»å¼ºè¡Œå¡è¿›ä¸Šä¸€è¡Œï¼ˆç¨åå¯èƒ½ä¼šåœ¨ Loop åº•éƒ¨è§¦å‘ Sentence End åˆ‡åˆ†ï¼‰
                        pass

            # --- æ­£å¸¸è¿½åŠ  ---
            current_words_buffer.append(word)
            current_len += w_len
            
            # --- è¯­ä¹‰å®Œç»“ç›´æ¥åˆ‡åˆ† (Post-split) ---
            # å¦‚æœç¢°åˆ°äº†å¼ºç»“æŸæ ‡ç‚¹ (. ? !)ï¼Œå¹¶ä¸”é•¿åº¦é€‚ä¸­ï¼ˆ>15å­—ï¼‰ï¼Œç›´æ¥åˆ‡åˆ†ï¼Œä¸ç•™ç€è¿‡å¹´
            curr_str = "".join([w["text"] for w in current_words_buffer]).strip()
            is_strong_end = curr_str and curr_str[-1] in ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ']
            
            if is_strong_end and current_len > 15:
                merged_segments.append({
                    "text": curr_str,
                    "start": current_words_buffer[0]["start"],
                    "end": current_words_buffer[-1]["end"]
                })
                current_words_buffer = []
                current_len = 0
        
        # è¡¥ä¸Šæœ€åä¸€æ®µ
        if current_words_buffer:
            merged_segments.append({
                "text": "".join([w["text"] for w in current_words_buffer]).strip(),
                "start": current_words_buffer[0]["start"],
                "end": current_words_buffer[-1]["end"]
            })

        # æ ¼å¼åŒ–è¾“å‡º
        if output_format == "srt":
            return self._format_as_srt_from_words(merged_segments)
        else:
            return "\n".join([s["text"] for s in merged_segments])

    def _format_as_srt_from_words(self, segments: List[Dict]) -> str:
        """ä»è‡ªå®šä¹‰ç‰‡æ®µç”Ÿæˆ SRT"""
        srt = ""
        for i, seg in enumerate(segments):
            # ã€ä¿®æ­£ã€‘JSON offsets å•ä½æ˜¯æ¯«ç§’ (ms)ï¼Œä¸éœ€è¦ x10
            start_ms = seg["start"]
            end_ms = seg["end"]
            
            def to_srt_time(total_ms):
                # ç¡®ä¿ total_ms æ˜¯æ•´æ•°
                total_ms = int(total_ms)
                h = total_ms // 3600000
                m = (total_ms % 3600000) // 60000
                s = (total_ms % 60000) // 1000
                ms = total_ms % 1000
                return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"

            srt += f"{i+1}\n"
            srt += f"{to_srt_time(start_ms)} --> {to_srt_time(end_ms)}\n"
            srt += f"{seg['text']}\n\n"
        return srt
        
        if current:
            merged_segments.append(current)

        # æ ¼å¼åŒ–è¾“å‡º
        if output_format == "srt":
            return self._format_as_srt(merged_segments)
        else:
            return "\n".join([s["text"].strip() for s in merged_segments])

    def _format_as_srt(self, segments: List[Dict]) -> str:
        """è§£æ JSON åç§»é‡å¹¶æ ¼å¼åŒ–ä¸º SRT"""
        srt = ""
        for i, seg in enumerate(segments):
            # ã€ä¿®æ­£ã€‘Whisper.cpp JSON offsets å•ä½ç¡®å®æ˜¯æ¯«ç§’ (ms)
            start_ms = seg["offsets"]["from"]
            end_ms = seg["offsets"]["to"]
            
            def to_srt_time(total_ms):
                total_ms = int(total_ms)
                h = total_ms // 3600000
                m = (total_ms % 3600000) // 60000
                s = (total_ms % 60000) // 1000
                ms = total_ms % 1000
                return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"

            srt += f"{i+1}\n"
            srt += f"{to_srt_time(start_ms)} --> {to_srt_time(end_ms)}\n"
            srt += f"{seg['text'].strip()}\n\n"
        return srt

    def transcribe_to_file(
        self,
        audio_path: str,
        output_path: str,
        output_format: str = "txt",
        verbose: bool = True
    ) -> bool:
        """
        è½¬å½•éŸ³é¢‘å¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶
        
        Args:
            audio_path: è¾“å…¥éŸ³é¢‘è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_format: è¾“å‡ºæ ¼å¼
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        result = self.transcribe(audio_path, output_format, verbose)
        
        if result['success']:
            # å¤åˆ¶åˆ°ç›®æ ‡ä½ç½®
            import shutil
            shutil.copy2(result['output_file'], output_path)
            
            # æ¸…ç†æ‰€æœ‰ç›¸å…³çš„ä¸´æ—¶æ–‡ä»¶ (json, srt, txt ç­‰)
            import glob
            output_base = result['output_file'].rsplit('.', 1)[0]
            for f in glob.glob(f"{output_base}*"):
                try:
                    os.unlink(f)
                except:
                    pass
            
            if verbose:
                print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
            return True
        
        return False
    
    def transcribe_to_desktop(
        self,
        audio_path: str,
        output_format: str = "srt"
    ) -> str:
        """
        æ€§èƒ½ä¼˜åŒ–ç‰ˆï¼šä¸€æ¬¡è½¬å½•ï¼ŒåŒæ—¶ä¿å­˜ SRT å’Œ TXT
        """
        # å‡†å¤‡è¾“å‡ºè·¯å¾„
        audio_name = Path(audio_path).stem
        
        # åˆ›å»ºç®¡ç†çš„è¾“å‡ºæ–‡ä»¶å¤¹ (åœ¨ Downloads ä¸‹)
        downloads = Path.home() / "Downloads"
        output_root = downloads / f"{audio_name}_output"
        output_root.mkdir(parents=True, exist_ok=True)
        
        # åªè¿è¡Œä¸€æ¬¡è½¬å½•ä»»åŠ¡ï¼Œè·å–æ ¸å¿ƒæ•°æ®
        # é»˜è®¤è¯·æ±‚ srt æ ¼å¼ï¼Œå†…éƒ¨ä¼šç”Ÿæˆ JSON å¹¶è¿›è¡Œæ™ºèƒ½å¤„ç†
        result = self.transcribe(audio_path, output_format="srt", verbose=True)
        
        if not result['success']:
            return None

        # 1. ä¿å­˜ SRT æ–‡ä»¶
        srt_path = output_root / f"{audio_name}.srt"
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(result['text'])
            
        # 2. ç”Ÿæˆå¹¶ä¿å­˜ TXT æ–‡ä»¶ (ç›´æ¥ä»ç»“æœä¸­æå–çº¯æ–‡æœ¬)
        # é€»è¾‘ï¼šå»é™¤æ—¶é—´æˆ³ï¼Œåªä¿ç•™æ–‡æœ¬å†…å®¹
        txt_path = output_root / f"{audio_name}.txt"
        lines = result['text'].split('\n')
        pure_text = []
        for line in lines:
            # è¿‡æ»¤æ‰ SRT çš„æ•°å­—ç´¢å¼•å’Œæ—¶é—´è½´è¡Œ
            if line.strip() and not line.strip().isdigit() and '-->' not in line:
                pure_text.append(line.strip())
        
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(" ".join(pure_text))
            
        # 3. å¤åˆ¶ JSON æ–‡ä»¶è¿‡æ¥ (ä½œä¸ºå¤‡ä»½å’Œæ•°æ®æº)
        if result.get('output_file'):
            src_json = Path(result['output_file']).with_suffix('.json')
            if src_json.exists():
                import shutil
                dst_json = output_root / f"{audio_name}.json"
                try:
                    shutil.copy2(src_json, dst_json)
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•å¤åˆ¶ JSON: {e}")

        if self.model_name == "large-v3":
            print(f"âœ¨ M4 æ€§èƒ½å…¨å¼€ä¼˜åŒ–ï¼šä¸€æ¬¡è¿è¡Œå·²åŒæ—¶ç”Ÿæˆ SRT å’Œ TXT")
        
        print(f"ğŸ’¾ æ‰€æœ‰æ–‡ä»¶å·²å½’æ¡£è‡³æ–‡ä»¶å¤¹: {output_root}")
                    
        return result['text']


# ä¾¿æ·å‡½æ•°
def transcribe_audio(
    audio_path: str,
    model: str = "small",
    language: str = "en",
    output_path: Optional[str] = None
) -> str:
    """
    ä¾¿æ·çš„è½¬å½•å‡½æ•°
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model: æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
        language: è¯­è¨€ä»£ç 
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¿å­˜åˆ° Downloads æ–‡ä»¶å¤¹ï¼Œç”Ÿæˆ .srt å’Œ .txtï¼‰
        
    Returns:
        è½¬å½•æ–‡æœ¬ (SRT æ ¼å¼)
    """
    whisper = WhisperCPP(model_name=model, language=language)
    
    if output_path:
        # å¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼Œæˆ‘ä»¬ä»ç„¶é»˜è®¤ç”Ÿæˆ srt
        if not output_path.endswith('.srt') and not output_path.endswith('.txt'):
            output_path += ".srt"
        whisper.transcribe_to_file(audio_path, output_path)
        with open(output_path, 'r', encoding='utf-8') as f:
            return f.read()
    else:
        return whisper.transcribe_to_desktop(audio_path)


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # æ–¹å¼ 1: ä½¿ç”¨ç±»
    print("=" * 60)
    print("æ–¹å¼ 1: ä½¿ç”¨ WhisperCPP ç±»")
    print("=" * 60)
    
    whisper = WhisperCPP(model_name="medium", threads=8)
    audio_file = "/Users/bogeling/Downloads/This game theory problem will change the way you see the world.mp4"
    
    # è½¬å½•åˆ°æ¡Œé¢
    text = whisper.transcribe_to_desktop(audio_file)
    print(f"\nğŸ“ è½¬å½•é¢„è§ˆ:\n{text[:500]}...\n")
    
    # æ–¹å¼ 2: ä½¿ç”¨ä¾¿æ·å‡½æ•°
    print("=" * 60)
    print("æ–¹å¼ 2: ä½¿ç”¨ä¾¿æ·å‡½æ•°")
    print("=" * 60)
    
    # text = transcribe_audio(audio_file, model="small")
    # print(f"\nğŸ“ è½¬å½•å®Œæˆï¼")
